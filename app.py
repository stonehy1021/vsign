import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
import cv2
import mediapipe as mp
import av
import numpy as np
import time
import queue

# ---------------- 1. ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="Smart Selfie (Face + V-sign)", layout="centered")
st.title("ğŸ“¸ Smart Selfie")
st.markdown("ì–¼êµ´ê³¼ **ë¸Œì´(V) í¬ì¦ˆ**ë¥¼ ì¸ì‹í•˜ë©´ 3ì´ˆ ë’¤ ìë™ìœ¼ë¡œ ì°ì–´ì¤ë‹ˆë‹¤! âœŒï¸")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "snapshot" not in st.session_state:
    st.session_state.snapshot = None

# Mediapipe ì´ˆê¸°í™”
mp_face = mp.solutions.face_detection
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

# ---------------- 2. í—¬í¼ í•¨ìˆ˜: Ví¬ì¦ˆ ì¸ì‹ ----------------
def is_victory(lms, w, h):
    """ì†ê°€ë½ ì¢Œí‘œë¥¼ ë¶„ì„í•´ V í¬ì¦ˆì¸ì§€ í™•ì¸"""
    def c(i):
        lm = lms.landmark[i]
        return int(lm.x * w), int(lm.y * h)

    # ì†ê°€ë½ ë(tip)ê³¼ ë§ˆë””(knuckle) ì¢Œí‘œ
    i_tip, m_tip = c(8), c(12)  # ê²€ì§€, ì¤‘ì§€ ë
    r_tip, p_tip = c(16), c(20) # ì•½ì§€, ìƒˆë¼ ë
    i_kn, m_kn = c(5), c(9)     # ê²€ì§€, ì¤‘ì§€ ë§ˆë””
    r_kn, p_kn = c(13), c(17)   # ì•½ì§€, ìƒˆë¼ ë§ˆë””

    # ê²€ì§€ì™€ ì¤‘ì§€ëŠ” í´ì ¸ ìˆê³ (ëì´ ë§ˆë””ë³´ë‹¤ ìœ„), ë‚˜ë¨¸ì§€ëŠ” ì ‘í˜€ ìˆì–´ì•¼ í•¨ (ì¢Œí‘œê³„ìƒ ìœ„ê°€ yê°’ì´ ì‘ìŒ)
    # í•˜ì§€ë§Œ ì† ë°©í–¥ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‹¨ìˆœí•˜ê²Œ ìƒëŒ€ì  ìœ„ì¹˜ ë¹„êµ
    # ì—¬ê¸°ì„œëŠ” ì†ì´ ìœ„ë¥¼ í–¥í•  ë•Œ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë¨ (ì¼ë°˜ì ì¸ V)
    
    # í´ì§ ì¡°ê±´: íŒì´ ê´€ì ˆë³´ë‹¤ ìœ„ì— ìˆìŒ (yê°’ì´ ì‘ìŒ)
    index_open = i_tip[1] < i_kn[1]
    middle_open = m_tip[1] < m_kn[1]
    
    # ì ‘í˜ ì¡°ê±´: íŒì´ ê´€ì ˆë³´ë‹¤ ì•„ë˜ì— ìˆìŒ (yê°’ì´ í¼)
    ring_folded = r_tip[1] > r_kn[1]
    pinky_folded = p_tip[1] > p_kn[1]

    return index_open and middle_open and ring_folded and pinky_folded

# ---------------- 3. ì˜ìƒ ì²˜ë¦¬ í´ë˜ìŠ¤ ----------------
class VideoProcessor(VideoProcessorBase):
    def __init__(self):
        # ëª¨ë¸ ë¡œë“œ
        self.face_detector = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6)
        self.hand_detector = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.6)
        
        self.result_queue = queue.Queue() # ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ì´ë¯¸ì§€ë¥¼ ë³´ë‚¼ í†µë¡œ
        self.capture_triggered = False
        self.enter_time = None
        self.flash_frame = 0

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1) # ê±°ìš¸ ëª¨ë“œ
        h, w, _ = img.shape
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # 1. ì–¼êµ´ ê°ì§€
        face_res = self.face_detector.process(rgb)
        face_detected = face_res.detections is not None

        # 2. ì† ê°ì§€ ë° V í¬ì¦ˆ í™•ì¸
        hand_res = self.hand_detector.process(rgb)
        victory_detected = False

        if hand_res.multi_hand_landmarks:
            for handLms in hand_res.multi_hand_landmarks:
                mp_draw.draw_landmarks(img, handLms, mp_hands.HAND_CONNECTIONS)
                if is_victory(handLms, w, h):
                    victory_detected = True
                    break
        
        if face_detected:
            for d in face_res.detections:
                mp_draw.draw_detection(img, d)

        # 3. ë¡œì§ íŒì • (ì–¼êµ´ + Ví¬ì¦ˆ)
        status_msg = "Show Face & V-sign"
        color = (0, 0, 255) # ë¹¨ê°•

        # í”Œë˜ì‹œ íš¨ê³¼
        if self.flash_frame > 0:
            self.flash_frame -= 1
            white = np.full((h, w, 3), 255, dtype=np.uint8)
            img = cv2.addWeighted(img, 0.5, white, 0.5, 0)

        if face_detected and victory_detected:
            color = (0, 255, 0) # ì´ˆë¡
            status_msg = "HOLD ON!"
            
            # ì¹´ìš´íŠ¸ë‹¤ìš´ ë¡œì§
            if self.enter_time is None:
                self.enter_time = time.time()
            
            elapsed = time.time() - self.enter_time
            countdown = 1.5 - elapsed # 1.5ì´ˆ ëŒ€ê¸°
            
            if countdown > 0:
                cv2.putText(img, f"{countdown:.1f}", (w//2-50, h//2), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 255), 4)
            else:
                # ì´¬ì˜ ì‹œì 
                if not self.capture_triggered:
                    self.result_queue.put(img) # íì— ì´ë¯¸ì§€ ë„£ê¸°
                    self.capture_triggered = True
                    self.flash_frame = 5
        else:
            self.enter_time = None
            self.capture_triggered = False

        # ìƒíƒœ ë©”ì‹œì§€ ì¶œë ¥
        cv2.putText(img, status_msg, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ---------------- 4. UI êµ¬ì„± ----------------

# 4-1. ê²°ê³¼ í™”ë©´ (ì´¬ì˜ í›„)
if st.session_state.snapshot is not None:
    st.success("ğŸ“¸ ì´¬ì˜ ì„±ê³µ!")
    st.image(st.session_state.snapshot, channels="BGR", caption="ë‚´ Vë¼ì¸ ìƒ·", use_container_width=True)
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    img_rgb = cv2.cvtColor(st.session_state.snapshot, cv2.COLOR_BGR2RGB) # ì €ì¥ìš© ë³€í™˜
    is_success, buffer = cv2.imencode(".jpg", st.session_state.snapshot) # OpenCV ê¸°ë³¸ì´ BGRì´ë¼ ê·¸ëŒ€ë¡œ ì¸ì½”ë”©
    
    if is_success:
        st.download_button(
            label="ğŸ“¥ ì‚¬ì§„ ë‹¤ìš´ë¡œë“œ",
            data=buffer.tobytes(),
            file_name=f"V_Selfie_{int(time.time())}.jpg",
            mime="image/jpeg",
            type="primary"
        )
    
    st.warning("ğŸ”„ ë‹¤ì‹œ ì°ìœ¼ë ¤ë©´ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”!")

# 4-2. ì´¬ì˜ í™”ë©´
else:
    ctx = webrtc_streamer(
        key="v-sign-camera",
        video_processor_factory=VideoProcessor,
        rtc_configuration=RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}),
        media_stream_constraints={"video": {"facingMode": "user"}, "audio": False},
    )

    # í í™•ì¸ ë£¨í”„ (ìë™ ì´¬ì˜ ê°ì§€)
    if ctx.state.playing:
        while True:
            if ctx.video_processor:
                try:
                    # í”„ë¡œì„¸ì„œì—ì„œ ë³´ë‚¸ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                    result_img = ctx.video_processor.result_queue.get(timeout=0.1)
                    if result_img is not None:
                        st.session_state.snapshot = result_img
                        st.rerun() # í™”ë©´ ê°±ì‹ 
                except queue.Empty:
                    pass
            time.sleep(0.1)
